# ğŸ˜Š Facial Emotion Recognition & Emoji Mapping System

This project is a **Facial Expression Recognition System** that detects human emotions from facial expressions using deep learning, and maps each detected emotion to a corresponding emoji. The system supports **image input**, **video input**, and **live camera feed**, and outputs both **emotion classification results** and **visual emoji representation**. Voice feedback is also integrated for accessibility and fun!

---

## ğŸš€ Features

- ğŸ­ Real-time facial emotion recognition using CNN / Pretrained Models (VGG16/ResNet50/EfficientNet).
- ğŸ“¸ Accepts input from:
  - Uploaded images
  - Uploaded videos
  - Live webcam feed
- ğŸ§  Trained on datasets like **CK+** and **AffectNet** for high accuracy.
- ğŸ˜„ Maps multiple emojis to each emotion randomly for variety.
- ğŸ”Š Emotion-specific **audio feedback** (e.g., laughter for happy, sigh for sad).
- ğŸ“Š Detailed **EDA and performance visualization**.
- ğŸ“± Deployed using **Streamlit** for a responsive UI.

---

## ğŸ§  Supported Emotions & Emojis

| Emotion       | Sample Emojis                     |
|---------------|-----------------------------------|
| Happy ğŸ˜€      | ğŸ˜„ ğŸ˜Š ğŸ˜ ğŸ˜‚ ğŸ¤©                     |
| Sad ğŸ˜¢        | ğŸ˜¢ ğŸ˜ ğŸ˜” ğŸ˜Ÿ ğŸ˜¿                     |
| Angry ğŸ˜       | ğŸ˜  ğŸ˜¡ ğŸ¤¬ ğŸ˜¤                        |
| Surprise ğŸ˜®   | ğŸ˜® ğŸ˜² ğŸ˜¯ ğŸ¤¯                        |
| Disgust ğŸ¤¢    | ğŸ¤¢ ğŸ¤® ğŸ˜– ğŸ¤§                        |
| Fear ğŸ˜±       | ğŸ˜± ğŸ˜¨ ğŸ˜° ğŸ˜¬                        |
| Neutral ğŸ˜    | ğŸ˜ ğŸ˜‘ ğŸ™ƒ ğŸ«¥                        |

---


---

## ğŸ› ï¸ Tech Stack

- **Python 3.10+**
- **TensorFlow / Keras** â€“ Model building and training
- **OpenCV** â€“ Video & webcam processing
- **Streamlit** â€“ Web app deployment
- **Pandas / Matplotlib / Seaborn** â€“ EDA
- **gTTS / Pygame / Playsound** â€“ Audio output
- **Haarcascade / Dlib** â€“ Face detection

---

## ğŸ“ˆ Dataset

- **CK+ (Extended Cohn-Kanade)**
- **AffectNet**  
(Combined for better accuracy, class balancing, and real-world applicability.)

---

## ğŸ§ª How to Run

1. **Clone the Repository**
   ```bash
   git clone https://github.com/your-username/facial-emotion-emoji-mapper.git
   cd facial-emotion-emoji-mapper/streamlit_app
Install Requirements

bash
Copy
Edit
pip install -r requirements.txt
Run the App

bash
Copy
Edit
streamlit run app.py
Choose Input Type

Upload image or video

Use webcam for live feed

Get Output

Emotion label + probability

Displayed emoji

Audio feedback

ğŸ“Š Model Accuracy
Training Accuracy: ~95%

Validation Accuracy: ~92%

Confusion matrix & detailed plots included in the app's EDA section.

ğŸŒŸ Future Enhancements
Integrate with AR filters for fun applications.

Deploy on mobile devices.

Add emotion tracking over time in live video.

ğŸ¤ Contributors
Your Name â€“ Lead Developer

Afiya â€“ Testing & Feedback

OpenAI ChatGPT â€“ Assistant & Architecture

ğŸ“œ License
MIT License â€“ free for personal and commercial use with attribution.

