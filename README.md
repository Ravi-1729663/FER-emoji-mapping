# ğŸ˜Š Facial Emotion Recognition & Emoji Mapping System

This project is a **Facial Expression Recognition System** that detects human emotions from facial expressions using deep learning, and maps each detected emotion to a corresponding emoji. The system supports **image input**, **video input**, and **live camera feed**, and outputs both **emotion classification results** and **visual emoji representation**. Voice feedback is also integrated for accessibility and fun!

---

## ğŸš€ Features

- ğŸ­ Real-time facial emotion recognition using CNN / Pretrained Models (VGG16/ResNet50/EfficientNet).
- ğŸ“¸ Accepts input from:
  - Uploaded images
  - Uploaded videos
  - Live webcam feed
- ğŸ§  Trained on datasets like **CK+** and **AffectNet** for high accuracy.
- ğŸ˜„ Maps multiple emojis to each emotion randomly for variety.
- ğŸ”Š Emotion-specific **audio feedback** (e.g., laughter for happy, sigh for sad).
- ğŸ“Š Detailed **EDA and performance visualization**.
- ğŸ“± Deployed using **Streamlit** for a responsive UI.

---

## ğŸ§  Supported Emotions & Emojis

| Emotion       | Sample Emojis                     |
|---------------|-----------------------------------|
| Happy ğŸ˜€      | ğŸ˜„ ğŸ˜Š ğŸ˜ ğŸ˜‚ ğŸ¤©                     |
| Sad ğŸ˜¢        | ğŸ˜¢ ğŸ˜ ğŸ˜” ğŸ˜Ÿ ğŸ˜¿                     |
| Angry ğŸ˜       | ğŸ˜  ğŸ˜¡ ğŸ¤¬ ğŸ˜¤                        |
| Surprise ğŸ˜®   | ğŸ˜® ğŸ˜² ğŸ˜¯ ğŸ¤¯                        |
| Disgust ğŸ¤¢    | ğŸ¤¢ ğŸ¤® ğŸ˜– ğŸ¤§                        |
| Fear ğŸ˜±       | ğŸ˜± ğŸ˜¨ ğŸ˜° ğŸ˜¬                        |
| Neutral ğŸ˜    | ğŸ˜ ğŸ˜‘ ğŸ™ƒ ğŸ«¥                        |

---


---

## ğŸ› ï¸ Tech Stack

- **Python 3.10+**
- **TensorFlow / Keras** â€“ Model building and training
- **OpenCV** â€“ Video & webcam processing
- **Streamlit** â€“ Web app deployment
- **Pandas / Matplotlib / Seaborn** â€“ EDA
- **gTTS / Pygame / Playsound** â€“ Audio output
- **Haarcascade / Dlib** â€“ Face detection

---

## ğŸ“ˆ Dataset

- **CK+ (Extended Cohn-Kanade)**
- **AffectNet**  
(Combined for better accuracy, class balancing, and real-world applicability.)

---

## ğŸ§ª How to Run

1. **Clone the Repository**
   ```bash
   git clone https://github.com/your-username/facial-emotion-emoji-mapper.git
   cd facial-emotion-emoji-mapper/streamlit_app


ğŸ“Š Model Accuracy
Training Accuracy: ~95%

Validation Accuracy: ~92%

Confusion matrix & detailed plots included in the app's EDA section.

